{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE5ZgC9s1t6L"
   },
   "source": [
    "Code created by Rafael Solar in Google colab.\n",
    "\n",
    "\n",
    "This program includes the training of a VGG16 convolutional network using a dataset containing five animal classes.\n",
    "\n",
    "The code is based on the content of Section 8 of the book F. Chollet, Python Deep Learning, Manning, 2nd ed., 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfxIUBpNw_MV",
    "outputId": "6dd195af-e4ee-40f0-a5d8-c9df3763d609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Connect to our files in Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-1XirD50lAJ"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries.\n",
    "import pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiwDTO4wLI24"
   },
   "outputs": [],
   "source": [
    "# Using the file path, we process the dataset into three groups: \"train,\" \"validation (val),\" and \"test.\"\n",
    "# Each group contains 5 classes: cat, dog, chicken, horse, and spider.\n",
    "\n",
    "path_drive_dataset = '/content/drive/MyDrive/Rafael_Solar_Hdez-Tesis-Lic/Programas/Modelo_Clasificacion-otono2022/dataset_animal'\n",
    "new_base_dir = pathlib.Path(path_drive_dataset)\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir/'train',\n",
    "    image_size=(180,180),\n",
    "    batch_size=32)\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    new_base_dir/'validation',\n",
    "    image_size=(180,180),\n",
    "    batch_size=32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir/'test',\n",
    "    image_size=(180,180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3fLh3MY0lAS"
   },
   "source": [
    "## Model implementing VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARYbSqxB0lAS",
    "outputId": "b1b8f9f0-676f-40d4-d206-99f51fead8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Implementing the base instance of the VGG16 convolutional network, freezing all layers, and excluding the top or classifier.\n",
    "conv_base_vgg = keras.applications.vgg16.VGG16(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,)\n",
    "\n",
    "# \"freeze\" the layers of the pre-trained model that we will not fine-tune, while leaving the last 4 layers to be adjusted with the dataset.\n",
    "conv_base_vgg.trainable = True\n",
    "for layer in conv_base_vgg.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yB3IbW8C3A7G",
    "outputId": "51c9b6f3-f07f-4681-c780-3fa025d5750f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base_vgg.summary() #VGG16 summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ozGVHFm0lAS"
   },
   "source": [
    "## Construction of the model that will train the last layers and our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdnMilEj0lAS"
   },
   "outputs": [],
   "source": [
    "# We apply the data augmentation technique with rotation and zoom parameters set to probabilities of 0.1 and 0.2.\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip('horizontal'),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Structure of the \"model_5animals\".\n",
    "# Image parameters: 180 pixels by 180 pixels, with 3 filters as they are RGB images.\n",
    "inputs = keras.Input(shape=(180,180,3))\n",
    "# Apply data augmentation to the input images.\n",
    "x = data_augmentation(inputs)\n",
    "# Preprocess the input image.\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "# Implement the VGG convolutional base without the classifier.\n",
    "x = conv_base_vgg(x)\n",
    "# Transform the network to adapt the dimension to a 1xn vector.\n",
    "x = layers.Flatten() (x)\n",
    "# Create a dense layer with 256 neurons.\n",
    "x = layers.Dense(256) (x)\n",
    "# Use dropout with a probability of 0.5.\n",
    "x = layers.Dropout(0.5) (x)\n",
    "# Define the network output \"5animals\" with 5 neurons, corresponding to the network's classes.\n",
    "outputs = layers.Dense(5, activation='softmax') (x)\n",
    "#---------------------------------------------\n",
    "# Construction of the \"5animals\" model\n",
    "model_5animals = keras.Model(inputs, outputs)\n",
    "#---------------------------------------------\n",
    "\n",
    "# Model compilation with the loss function, optimizer, and metrics.\n",
    "model_5animals.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer= keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUrYo0WtSuZj",
    "outputId": "5ac7e4f0-d362-4b7a-d149-d35fc134d9a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_3   (None, 180, 180, 3)      0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " tf.nn.bias_add_3 (TFOpLambd  (None, 180, 180, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               3277056   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,993,029\n",
      "Trainable params: 10,357,765\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5animals.summary() #Our neuronal network summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Si9se3ch0lAS"
   },
   "source": [
    "## Training the 5animals model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLgRkYxi0lAS",
    "outputId": "bc6ea931-5c3f-452f-8ee4-84c12e4f36d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 2803s 17s/step - loss: 5.6841 - accuracy: 0.6232 - val_loss: 0.8189 - val_accuracy: 0.8728\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 36s 228ms/step - loss: 1.0858 - accuracy: 0.7838 - val_loss: 0.5028 - val_accuracy: 0.9060\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 36s 225ms/step - loss: 0.6712 - accuracy: 0.8380 - val_loss: 0.3427 - val_accuracy: 0.9316\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 36s 225ms/step - loss: 0.5094 - accuracy: 0.8748 - val_loss: 0.2740 - val_accuracy: 0.9464\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 36s 228ms/step - loss: 0.3587 - accuracy: 0.8992 - val_loss: 0.2714 - val_accuracy: 0.9512\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 36s 225ms/step - loss: 0.2906 - accuracy: 0.9240 - val_loss: 0.2677 - val_accuracy: 0.9524\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 36s 224ms/step - loss: 0.2246 - accuracy: 0.9372 - val_loss: 0.2430 - val_accuracy: 0.9584\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 36s 225ms/step - loss: 0.1882 - accuracy: 0.9442 - val_loss: 0.2339 - val_accuracy: 0.9640\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 36s 224ms/step - loss: 0.1797 - accuracy: 0.9516 - val_loss: 0.2503 - val_accuracy: 0.9632\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 36s 224ms/step - loss: 0.1465 - accuracy: 0.9568 - val_loss: 0.3181 - val_accuracy: 0.9684\n"
     ]
    }
   ],
   "source": [
    "# Training of the 5animals neural network.\n",
    "\n",
    "history = model_5animals.fit(\n",
    "    train_dataset,\n",
    "    epochs = 10,\n",
    "    validation_data = val_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RALli3R-WvJg"
   },
   "source": [
    "### Print the accuracy on the original training set and the animal testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1BILMYk0lAS",
    "outputId": "bd0c7069-54df-47a0-ec29-11563a4181a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 19s 115ms/step - loss: 0.0800 - accuracy: 0.9852\n",
      "Test accuracy using training set: 0.985\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_5animals.evaluate(train_dataset) # training\n",
    "print(f\"Test accuracy using training set: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWWX0XuKffai",
    "outputId": "c4c0ebb5-e8e1-4b4c-cdc4-8272f74be381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2096s 13s/step - loss: 0.2121 - accuracy: 0.9700\n",
      "Test accuracy using test set: 0.970\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_5animals.evaluate(test_dataset) #testing\n",
    "print(f\"Test accuracy using test set: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fo5QhI8BW-aq"
   },
   "source": [
    "### Save the trained model model_5animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gG2X9pMj0lAS"
   },
   "outputs": [],
   "source": [
    "#Guardar el modelo 5animales entrenado\n",
    "!mkdir -p saved_model\n",
    "model_5animals.save('...models_save_path/model5animales.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "9f1f23882f45b9a30a1a22743a54a9341959cc9f971cf3ae44b8c755981f05b6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
